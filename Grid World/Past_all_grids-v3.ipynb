{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_ROWS = 3\n",
    "BOARD_COLS = 4\n",
    "START = (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State:\n",
    "\n",
    "    def __init__(self, state=START):\n",
    "        self.board = np.zeros([BOARD_ROWS, BOARD_COLS])\n",
    "        self.state = state    # tuple of the coordinate\n",
    "        self.is_end = False\n",
    "\n",
    "    def check_end(self):\n",
    "        if self.state == START:\n",
    "            self.is_end = True\n",
    "\n",
    "    def next_position(self, action):\n",
    "        if action == \"up\":\n",
    "            next_state = (self.state[0] - 1, self.state[1])\n",
    "        elif action == \"down\":\n",
    "            next_state = (self.state[0] + 1, self.state[1])\n",
    "        elif action == \"left\":\n",
    "            next_state = (self.state[0], self.state[1] - 1)\n",
    "        else:\n",
    "            next_state = (self.state[0], self.state[1] + 1)\n",
    "        if (next_state[0] >= 0) and (next_state[0] < BOARD_ROWS):\n",
    "            if (next_state[1] >= 0) and (next_state[1] < BOARD_COLS):\n",
    "                return next_state\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.actions = [\"up\", \"down\", \"left\", \"right\"]  # space\n",
    "        self.State = State()\n",
    "        self.is_end = self.State.is_end\n",
    "        self.alpha = 0.05\n",
    "        self.exp_rate = 1\n",
    "        self.decay_gamma = 0.9\n",
    "        self.Q_values = {}  # init Q values (dict)\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                self.Q_values[(i, j)] = {}\n",
    "                for a in self.actions:\n",
    "                    self.Q_values[(i, j)][a] = 0\n",
    "        self.past_all = []\n",
    "        for i in range(BOARD_ROWS):\n",
    "            t = []\n",
    "            for j in range(BOARD_COLS):\n",
    "                t.append(False)\n",
    "            self.past_all.append(t)\n",
    "\n",
    "        self.steps = []\n",
    "        self.stop = False\n",
    "        self.step = 0\n",
    "        self.states=[]\n",
    "        self.all_states=[]\n",
    "\n",
    "    def optimal_action(self):\n",
    "        max_value = -10000\n",
    "        action = \"\"\n",
    "        for a in self.actions:\n",
    "            next_value = self.Q_values[self.State.state][a]\n",
    "            if next_value >= max_value:\n",
    "                action = a\n",
    "                max_value = next_value\n",
    "        return action\n",
    "\n",
    "    def get_actions(self):\n",
    "        i, j = self.State.state[0], self.State.state[1]\n",
    "        potential_position = []\n",
    "        if i + 1 < BOARD_ROWS:\n",
    "            potential_position.append(\"down\")\n",
    "        if i - 1 > 0:\n",
    "            potential_position.append(\"up\")\n",
    "        if j + 1 < BOARD_COLS:\n",
    "            potential_position.append(\"right\")\n",
    "        if j - 1 > 0:\n",
    "            potential_position.append(\"left\")\n",
    "        return potential_position\n",
    "\n",
    "#     def get_action(self):\n",
    "#         \"\"\"\n",
    "#         The agent should choose randomly among the positions that have\n",
    "#         not been visited, and if all possible positions are visited,\n",
    "#         then move randomly and receive a negative reward\n",
    "#         \"\"\"\n",
    "#         actions = self.get_actions()\n",
    "#         if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "#             b = True\n",
    "#             for a in actions:\n",
    "#                 position = self.State.next_position(a)\n",
    "#                 if self.past_all[position[0]][position[1]] is False:\n",
    "#                     b = False\n",
    "#             if b:\n",
    "#                 action = np.random.choice(actions)\n",
    "#                 return action\n",
    "#             # Else try to get an available unvisited position randomly\n",
    "#             else:\n",
    "#                 while True:\n",
    "#                     action = np.random.choice(actions)\n",
    "#                     next_state = self.State.next_position(action)\n",
    "#                     if self.past_all[next_state[0]][next_state[1]] is False:\n",
    "#                         return action\n",
    "#                     else:\n",
    "#                         continue\n",
    "#         else:\n",
    "#             return self.optimal_action()\n",
    "\n",
    "    def get_action(self):\n",
    "        actions = self.get_actions()\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            return np.random.choice(actions)\n",
    "        else:\n",
    "             return self.optimal_action()\n",
    "\n",
    "\n",
    "    def give_reward(self):\n",
    "        reward = 0\n",
    "        if self.State.state == START and self.check_all_past():\n",
    "            reward += 1\n",
    "#         else:   \n",
    "#             reward -= (BOARD_ROWS*BOARD_COLS-self.step)\n",
    "        return reward\n",
    "\n",
    "    def set_action(self, action):\n",
    "        self.step += 1\n",
    "        curr_state = self.State.state\n",
    "        \n",
    "        self.states.append(curr_state)\n",
    "        \n",
    "        self.past_all[curr_state[0]][curr_state[1]] = True\n",
    "        next_state = self.State.next_position(self.get_action())\n",
    "        self.State = State(state=next_state)\n",
    "        reward = self.give_reward()\n",
    "        if self.past_all[next_state[0]][next_state[1]] is False:\n",
    "            self.past_all[next_state[0]][next_state[1]] = True\n",
    "        else:\n",
    "            reward -= 1\n",
    "            self.stop = True\n",
    "        qs_of_next_state = []\n",
    "        for q_value in self.Q_values[next_state]:\n",
    "            qs_of_next_state.append(self.Q_values[next_state][q_value])\n",
    "        delta = self.alpha * (reward + self.decay_gamma * (max(qs_of_next_state)) -\n",
    "                              self.Q_values[curr_state][action])\n",
    "        self.Q_values[curr_state][action] = round(self.Q_values[curr_state][action] + delta, 10)\n",
    "\n",
    "    def reset(self):\n",
    "        for i in range(BOARD_ROWS):\n",
    "            for j in range(BOARD_COLS):\n",
    "                self.past_all[i][j] = False\n",
    "        self.State = State()\n",
    "        self.is_end = self.State.is_end\n",
    "        self.stop = False\n",
    "        self.step = 0\n",
    "        self.states=[]\n",
    "\n",
    "    def check_all_past(self):\n",
    "        for i in self.past_all:\n",
    "            for j in i:\n",
    "                if j is False:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def train(self, rounds=10000):\n",
    "        print(\"Training...\")\n",
    "        for r in range(rounds):\n",
    "            self.reset()\n",
    "            self.exp_rate *= 0.99\n",
    "            step = 0\n",
    "            while True:\n",
    "                action = self.get_action()\n",
    "                self.set_action(action)\n",
    "                self.State.check_end()\n",
    "                self.is_end = self.State.is_end\n",
    "                step += 1\n",
    "                if self.is_end and self.check_all_past():\n",
    "                    self.all_states.append(self.states)\n",
    "                    break\n",
    "                if self.stop:\n",
    "                    self.all_states.append(self.states)\n",
    "                    break\n",
    "            self.steps.append(step)\n",
    "        print(\"Training finished!\")\n",
    "\n",
    "    def show_path(self):\n",
    "        for i in range(BOARD_ROWS):\n",
    "            print('---------------------------------------')\n",
    "            row_string = \"| \"\n",
    "            for j in range(BOARD_COLS):\n",
    "                best_move = \"\"\n",
    "                best_val = -100000000\n",
    "                for a in self.Q_values[(i,j)]:\n",
    "                    if self.Q_values[(i, j)][a] > best_val:\n",
    "                        best_val = self.Q_values[(i,j)][a]\n",
    "                        best_move = a\n",
    "                row_string = row_string + \" \" + best_move + \" |\"\n",
    "            print(row_string)\n",
    "        print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Training finished!\n",
      "{(0, 0): {'up': -0.6308530711, 'down': -0.6042323031, 'left': -0.6305934747, 'right': -0.48180593}, (0, 1): {'up': -0.9405812056, 'down': -0.9148481815, 'left': -0.9168832637, 'right': -0.5353399233}, (0, 2): {'up': -0.8168353163, 'down': -0.7881908789, 'left': -0.7762993456, 'right': -0.5948221381}, (0, 3): {'up': -0.9053928845, 'down': -0.6609134878, 'left': -0.8986789584, 'right': -0.9101058595}, (1, 0): {'up': -1.248121851, 'down': -1.2473169545, 'left': -1.2695190941, 'right': -1.2436253361}, (1, 1): {'up': -1.38296914, 'down': -1.4032681033, 'left': -1.3841626368, 'right': -1.38180593}, (1, 2): {'up': -1.5353399233, 'down': -1.5448256322, 'left': -1.5543399657, 'right': -1.5377677257}, (1, 3): {'up': -0.9572762272, 'down': -0.7343483208, 'left': -0.9432260551, 'right': -0.9538951971}, (2, 0): {'up': -1.1192628015, 'down': -1.4737694805, 'left': -1.4488600527, 'right': -1.4755809644}, (2, 1): {'up': -1.2900070737, 'down': -1.2998631379, 'left': -1.0073365204, 'right': -1.3135558121}, (2, 2): {'up': -1.1698005341, 'down': -1.1777975703, 'left': -0.9066028674, 'right': -1.182404892}, (2, 3): {'up': -1.0719020431, 'down': -1.0444983311, 'left': -0.8159425797, 'right': -1.0469737254}}\n"
     ]
    }
   ],
   "source": [
    "agent = Agent()\n",
    "start_time = datetime.datetime.now()\n",
    "agent.train()\n",
    "end_time = datetime.datetime.now()\n",
    "time_period = (end_time - start_time).total_seconds()\n",
    "print(agent.Q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time:  1.932378\n"
     ]
    }
   ],
   "source": [
    "print(\"Running time: \", time_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "|  right | right | right | down |\n",
      "---------------------------------------\n",
      "|  right | right | up | down |\n",
      "---------------------------------------\n",
      "|  up | left | left | left |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "agent.show_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "x = []\n",
    "for i in range(10000):\n",
    "    x.append(i)\n",
    "y = agent.steps\n",
    "plt.plot(x,y)\n",
    "plt.ylabel('Number of Steps')\n",
    "plt.xlabel('Episode')\n",
    "plt.title('Q Learning Convergence')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
